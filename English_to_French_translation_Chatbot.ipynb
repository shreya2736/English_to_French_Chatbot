{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Welcome to the French Tutor Chatbot project - TuteurAI :)**"
      ],
      "metadata": {
        "id": "Z2RsGyBhuFqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#installing google genai library\n",
        "!pip install -q -U google-genai"
      ],
      "metadata": {
        "id": "vsxRGkg8iixG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#installing transformers library\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_xozLQ_j1EV",
        "outputId": "cbde8427-fe9b-40b6-b9db-4408b827ec79"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.55.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentencepiece is used by the pipeline internally\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "042PHAsQj5n8",
        "outputId": "c90d455a-2b98-4f17-8d7d-b26381579702"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# used by transformers library along with models like facebook/nllb-200-distilled-600M via pipeline\n",
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozv0rPe6j-lY",
        "outputId": "f0483e90-1c0d-42fa-b5a4-949dd49bdce3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import pipeline from transformers library\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "XLV1dkDwl2mQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialise the pipeline for translation : source_language=English target_language=French\n",
        "translator=pipeline(\"translation\",src_lang=\"eng_Latn\",tgt_lang=\"fra_Latn\",model=\"facebook/nllb-200-distilled-600M\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icWTu2ngmDvH",
        "outputId": "fde564ca-8a40-49e0-a7b1-6db108d259ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the pipeline by giving an english sentence as input\n",
        "input_sentence=input(\"enter your sentence and the model will translate to french:\")\n",
        "result=translator(input_sentence)\n",
        "print(\"output:\",result[0][\"translation_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4vPpLtmnTD4",
        "outputId": "87b43ecc-12b6-4ef6-98ac-52bf463a5046"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter your sentence and the model will translate to french:hi nice to meet you\n",
            "output: Bonjour, Ravi de vous rencontrer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# time library for the animated typing effect\n",
        "# genai library for using various tools in it for accessing the gemini models\n",
        "# userdata from colab to get the api key stored in secrets\n",
        "import time\n",
        "from google import genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "EAjUbWDziotP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for a real time typing effect\n",
        "def stream(text,user_input):\n",
        "  print(\"Tuteur : \")\n",
        "  print(\"YOUR QUESTION IN FRENCH : \",end=\" \")\n",
        "  qns=user_input.split(\".\")\n",
        "  qn_result=translator(qns)\n",
        "  for w in qn_result:\n",
        "    print(w[\"translation_text\"],end=\" \")\n",
        "  print()\n",
        "  print(\"MY ANSWER IN ENGLISH : \",end=\" \")\n",
        "  e_words=text.split(\" \")\n",
        "  for w in e_words:\n",
        "    print(w,end=\" \",flush=True)\n",
        "    time.sleep(0.1)\n",
        "  print()\n",
        "  print(\"MY ANSWER IN FRENCH : \",end=\" \")\n",
        "  answers=text.split(\".\")\n",
        "  ch_ans=translator(answers)\n",
        "  for w in ch_ans:\n",
        "    for i in w[\"translation_text\"]:\n",
        "      print(i,end=\" \",flush=True)\n",
        "      time.sleep(0.1)\n",
        "  print()"
      ],
      "metadata": {
        "id": "5lqr39yZiwWV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to retrieve the api key stored in secrets and store it in the variable 'key'\n",
        "key=userdata.get(\"MY_API_KEY\")"
      ],
      "metadata": {
        "id": "z-b_d1G_kepo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to establish the connection with the gemini api to access gemini models\n",
        "# llm api integration\n",
        "try:\n",
        "  client=genai.Client(api_key=key)\n",
        "except KeyError as e:\n",
        "  print(f\"key error occurred:{e}\")\n"
      ],
      "metadata": {
        "id": "RS4JT4JXkpqb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialising the chatbot\n",
        "chatbot=client.chats.create(model=\"gemini-2.0-flash\")"
      ],
      "metadata": {
        "id": "yFX5hho_lQzn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sending the user prompt to gemini ai through gemini api\n",
        "# poetic response function\n",
        "def ask_gemini(user_input):\n",
        "  try:\n",
        "    prompt=f\"Respond correctly for the user's question like a friend. Here is the question:{user_input}\"\n",
        "    response=chatbot.send_message(prompt)\n",
        "    return response.text\n",
        "  except Exception as e:\n",
        "    print(f\"Ooops!! An Exeception occurred: {e}\")\n"
      ],
      "metadata": {
        "id": "kRetMTLZlUku"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# starting the chatbot loop\n",
        "print(\"WELCOME TO YOUR FRENCH TUTOR CHATBOT - I AM 'TUTEUR AI' !!! I WILL HELP YOU LEARN FRENCH !!\")\n",
        "print()\n",
        "print(\"TYPE quit TO EXIT *****************************************************\")\n",
        "print()\n",
        "while True:\n",
        "  ui=input(\"YOU : \")\n",
        "  print()\n",
        "  if ui.lower()==\"quit\":\n",
        "    print(\"Tuteur: See you later !! :) bye for now\")\n",
        "    break\n",
        "  reply=ask_gemini(ui)\n",
        "  stream(reply,ui)\n",
        "  print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFUAWxeJro_N",
        "outputId": "bf59d4a2-c0bf-4326-f58d-499c7173f0d8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WELCOME TO YOUR FRENCH TUTOR CHATBOT - I AM 'TUTEUR AI' !!! I WILL HELP YOU LEARN FRENCH !!\n",
            "\n",
            "TYPE quit TO EXIT *****************************************************\n",
            "\n",
            "YOU : hi nice to meet you\n",
            "\n",
            "Tuteur : \n",
            "YOUR QUESTION IN FRENCH :  Bonjour, Ravi de vous rencontrer. \n",
            "MY ANSWER IN ENGLISH :  Hey! Nice to meet you too! ðŸ˜Š What's up?\n",
            " \n",
            "MY ANSWER IN FRENCH :  B o n j o u r ,   j e   s u i s   r a v i e   d e   v o u s   r e n c o n t r e r   a u s s i . \n",
            "\n",
            "YOU : whats the weather today in chennai\n",
            "\n",
            "Tuteur : \n",
            "YOUR QUESTION IN FRENCH :  Quelle est la mÃ©tÃ©o aujourd'hui Ã  Chennai ? \n",
            "MY ANSWER IN ENGLISH :  Ugh, Chennai weather! Let me check... Okay, it looks like it's pretty hot today, around 34Â°C (93Â°F). The humidity is also high, so be prepared for it to feel even warmer. Definitely stay hydrated! Anything fun planned despite the heat?\n",
            " \n",
            "MY ANSWER IN FRENCH :  L a   m Ã© t Ã© o   d e   C h e n n a i ,   l a i s s e - m o i   v Ã© r i f i e r . L e   d Ã© p Ã´ t L e   d Ã© p Ã´ t O k ,   i l   s e m b l e   q u ' i l   f a i t   t r Ã¨ s   c h a u d   a u j o u r d ' h u i ,   a u t o u r   d e   3 4 Â° C . L ' h u m i d i t Ã©   e s t   Ã© g a l e m e n t   Ã© l e v Ã© e ,   a l o r s   p r Ã© p a r e z - v o u s   Ã    s e   s e n t i r   e n c o r e   p l u s   c h a u d . Q u e l q u e   c h o s e   d ' a m u s a n t   p r Ã© v u   m a l g r Ã©   l a   c h a l e u r   ? \n",
            "\n",
            "YOU : quit\n",
            "\n",
            "Tuteur: See you later !! :) bye for now\n"
          ]
        }
      ]
    }
  ]
}